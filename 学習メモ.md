# データ加工(1,2章)

## pandasによるデータ加工

```python
"""
aとbを縦に結合(ユニオン)する
"""
pd.concat([a,b])
```
```python
"""
aとbを横に結合(ジョイン)する
on: 紐付けキー
how: ジョイン方向
left_on,right_on: 一致しない列名で結合する際に使用
"""
pd.merge(a,b,on="id",how="left")
```
```python
"""
欠損値をTrue/Falseで返す
"""
pd.isnull()
```
```python
"""
各種統計量の算出
件数、平均、標準偏差、最小、最大、中央値、四分位数
"""
pd.describe()
```
```python
pd.pivot_table(join_data,index="item_name",columns="payment_month",values=["price","quantity"],aggfunc="sum")
```
```python
"""
条件に合致するデータの抜き出し
"""
pd.loc(条件式, 列名)
"""
インデックスによるデータの抜き出し
"""
iloc(インデックス, 列名)
```

```python
pd.min(skipna=False): Nanデータを無視するかのフラグ Falseにすると最小値はNaNになる可能性がある
str.isdigit(): 文字列が数字か判定
```
```python
- pd.to_timedelta(df, unit="D") + pd.to_datetime("1900/01/01")
  - Excelなどでシリアル値に変換された値を日付に変換する
  - pythonとExcelで2日ずれる？
- df(series).where('条件', false値)
  - 条件がTrueの際は元の値のまま(指定不可)
  - false値を省略するとNaNが返るので注意
groupby()
```

## matplotlibによるグラフ化
matplotlib.pyplot.plot()

dt.strftime("%Y%m")
ユニークデータ件数の算出
pd.unique()  


# 機械学習(3-5章)

## pandas
rename(columns={"log_id":"count"}, inplace=True)
.dt.weekday

日時の差を計算するライブラリ
relativedelta

## クラスタリング
- 決められた正解がないデータを分類する場合、教師なし学習が適している
  - その1つがクラスタリング(グループに分ける)
- グラフ等による可視化のために、データを2次元まで`次元削減`する必要がある
  - 代表的な手法が`主成分分析(PCA)`

```python
# 標準化
from sklearn.preprocessing import StandardScaler
sc.fit_transform(df)
```

## 回帰
- 教師あり学習の一種
  - ここでは特に`線形回帰`を使用する

```python
from sklearn import linear_model # 線形回帰モデル
from sklearn.model_selection import train_test_split
# モデルの的中率(スコア)算出
model.score(X, y)
# 寄与している変数の寄与係数(重要度)
model.coef_
```
pd.dropna()

dropna(subset=["name"])
```python
# 全体のデータをサンプリング(シャッフル)
df.sample(frac=1).reset_index(drop=True)
# 重複削除
df.drop_duplicates(subset="列名")

pd.isna()
# カテゴリカル変数→ダミー変数
# 実質的に不要な列が作成される場合が多いので要整理
pd.get_dummies(df)
```
## 決定木
- `GraphViz`等を使うことで木構造の可視化もできる
```python
from sklearn.tree import DecisionTreeClassifier
# max_depth: 決定木の深さの上限
model = DecisionTreeClassifier(random_state=0,max_depth=5)
# 決定木における重要変数の取得
model.feature_importances_

model.predict(df) # 予測
model.predict_proba(df) # 確率/割合の予測
```

# 最適化問題(6-8章)
## ビジネス知識
- データ分析や最適化問題において重要なのは、ライブラリの使い方や計算方法だけでなく、現場の意思決定者を納得させてプランを採用させること
  - `可視化`は重要
  - 提示された条件や課題を満たしていることの証明が重要
- 最適化問題とは、`目的関数`を`制約条件`の元で解くこと
- ルートは少ないほうがコスト削減につながる？
- ロジスティックネットワーク(物流ネットワーク)
- 線形最適化
  - 輸送最適化問題
- ライブラリによる計算結果を鵜呑みにせず、妥当性を検算などによって確認する姿勢が重要
- 妥当性の検証や条件設定を人間の手でやるには限界がある
  - `数値シミュレーション`による将来予測で上記をサポートする
  - 特に人間関係のネットワーク構造を用いた数値シミュレーション
- 拡散,消滅の確率が普及にどのように影響するかを俯瞰するには`相関`を描くのが良い
- 大人数だとネットワークを可視化しても密集していて状況を掴みづらい
- ネットワーク構造の種類
  - スモールワールド型(少ないステップで全員が繋がる)
  - スケールフリー型(少数の繋がりを極めて多く持つ人がハブになる)
    - ハブが機能しないと途端に広がらなくなる
  - これらの型のリンク数の分布は`べき分布`に近いものとなる

## ネットワーク最適化

### NetworkX
- ネットワーク可視化のためのライブラリ
```python
import networkx as nx
import matplotlib.pyplot as plt
# オブジェクトの作成
G=nx.Graph()
# 頂点の設定
G.add_node("nodeA")
# 辺の設定
G.add_edge("nodeA","nodeB")
# 座標の設定
pos={}
pos["nodeA"]=(0,0)
# 描画
"""
オプション
with_labels=boolean :頂点のラベルを可視化
font_size
node_size
node_color
font_color
width: 重みリストによる重みづけしたリンクの描画
→ リンク(辺)の設定の順番と重みリストの順番を同じにする必要がある為、同じfor文で行うのが良い
"""
nx.draw(G,pos)
# 表示
plt.show()
```

### pulp, ortoolpy
- pulp: 最適化モデル作成ライブラリ
- ortoolpy: 目的関数を生成して解くライブラリ
#### 最適化モデルの記述方法
1. 問題を定義(最大化、最小化等)
2. 変数を定義
3. 係数をセット
4. 目的関数をセット
5. 制約条件をセット
6. 求解
```python
from itertools import product
# 組み合わせのタプル
product((0,1),(2,3))

from pulp import LpVariable, lpSum, value
from ortoolpy import model_max, model_min

# 最小化、最大化のモデル定義
model = model_max()
model = model_min()

# (数学的な意味での)変数の定義
"""
option
lowBound: 下限(-∞がデフォ)
upBound: 無限(∞がデフォ)
cat: 変数のタイプを設定
"""
x = LpVariable('変数名')

# 目的関数のセット(lpDot等でも可)
# 上で定義した変数を使用する
# lpSumは高速なsum？目的関数や制約条件の定義に最適
model += lpSum(関数)

# 制約条件をセット
model += lpSum(条件式)
# 求解
model.solve()
# 求解後の変数の値を取得
value(x)

# 最適化関数を取得する
# value()を使用することで解を代入した際の値が取得できる
model.objective

# ロジスティック
from ortoolpy import logistics_network
_, tbdi2, _ = logistics_network(tbde,tbdi,tbfa)

# ValY: 最適生産量
print(tbfa)
# ValX: 最適輸送量
print(tbdi2)
```

# データ結合とデータ正規化(おまけ)
- 冗長性
  - 本質的に同じであるデータを複数レコードに跨って持つことにより、updateの際に複数レコードを更新しなければならない状態のこと
- 教師あり学習
  - 予測する為の線を引くことが学習に当たる
  - 分類
    - 離散値の場合(〇〇する/しない)
    - 決定木,ロジスティック回帰,ランダムフォレストなど
  - 回帰
    - 連続値の場合(〇回)
    - 重回帰,勾配Bosting法など
- 教師なし学習
  - クラスタリングなど
  - 正解がないためモデルの精度が決められず、人間の知見による所が大きい
- 強化学習
  - 一連の行動に対して報酬などを与え、最も報酬が高くなる手段を学習させる